{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de9e4a0",
   "metadata": {},
   "source": [
    "# Computer Exercise 1: Estimation and Model Validation\n",
    "**Time Series Analysis - Lund University - 2025**\n",
    "\n",
    "This computer exercise treats identification, estimation, and model validation in ARMA- and SARIMA-processes. The focus is on simulating different kinds of stationary and non-stationary time series, and on how one may then identify a suitable model structure mainly using the autocorrelation function (ACF) and the partial autocorrelation function (PACF). In the exercise, we will examine both simulated and measured time series data.\n",
    "\n",
    "## 1. Preparations before the exercise\n",
    "\n",
    "Read Chapter 3 and 4 in the course textbook as well as this guide to the computer exercise. Solve the problem exercises 3.6, 3.10, 4.3, 4.4, and 5.2 in the book. Answers to some of the computer exercise will be graded using the course's **Mozquizto** page.\n",
    "\n",
    "Ensure that you can access the system before the exercise and answer the preparatory questions as well as (at least) three of numbered exercise questions below **before the exercise**.\n",
    "\n",
    "You can find the **Mozquizto** system at: `https://quizms.maths.lth.se`\n",
    "\n",
    "It should be stressed that a thorough understanding of the material in this exercise is important to be able to complete the course project, and we encourage you to discuss any questions you might have on the exercises with the teaching staff. This will save you a lot of time when you start working with the project!\n",
    "\n",
    "You are allowed to solve the exercise in groups of two, but not more. Please respect this.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 2. Tasks\n",
    "\n",
    "The computer program Python and functions from the course Python package will be used: `https://github.com/andreasjak/TimeSeriesAnalysis`\n",
    "\n",
    "**Important:** In the following, we will make use of various Python functions from the tsa_lth library.\n",
    "\n",
    "**Hint:** Create separate functions for different subtasks, you will likely need to use the same code several times, and this both saves time and helps you to debug your code efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fdce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import scipy.io\n",
    "\n",
    "# Add path to tsa_lth library\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'TimeSeriesAnalysis-main', 'TimeSeriesAnalysis-main')))\n",
    "\n",
    "# Import and reload to get the latest changes\n",
    "import tsa_lth.analysis\n",
    "import tsa_lth.modelling\n",
    "import tsa_lth.tests\n",
    "importlib.reload(tsa_lth.analysis)\n",
    "importlib.reload(tsa_lth.modelling)\n",
    "importlib.reload(tsa_lth.tests)\n",
    "\n",
    "from tsa_lth.analysis import plotACFnPACF, normplot, xcorr, pzmap, kovarians\n",
    "from tsa_lth.modelling import estimateARMA, polydiv\n",
    "from tsa_lth.tests import whiteness_test, check_if_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3adb89",
   "metadata": {},
   "source": [
    "## 2.1 Working with time series\n",
    "\n",
    "In this first section, we will work with two sets of A- and C-polynomials, the first set being:\n",
    "\n",
    "```python\n",
    "A1 = [1, -1.79, 0.84]\n",
    "C1 = [1, -0.18, -0.11]\n",
    "```\n",
    "\n",
    "and the second set:\n",
    "\n",
    "```python\n",
    "A2 = [1, -1.79]\n",
    "C2 = [1, -0.18, -0.11]\n",
    "```\n",
    "\n",
    "These polynomials builds an ARMA-process of the form\n",
    "\n",
    "$$A(z) y_t = C(z) e_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef22fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the two ARMA models\n",
    "A1 = np.array([1, -1.79, 0.84])\n",
    "C1 = np.array([1, -0.18, -0.11])\n",
    "\n",
    "A2 = np.array([1, -1.79])\n",
    "C2 = np.array([1, -0.18, -0.11])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc46856",
   "metadata": {},
   "source": [
    "An easy way to simulate an ARMA-process\n",
    "\n",
    "$$y_t=\\frac{C(z)}{A(z)}e_t$$\n",
    "\n",
    "in Python is to use the `signal.lfilter` function. The function needs the $A(z)$ and $C(z)$ polynomials as well as the driving noise process to generate a simulation. To allow for easy comparison with the values used in the **Mozquizto** system, set the random seed using\n",
    "\n",
    "```python\n",
    "np.random.seed(0)\n",
    "```\n",
    "\n",
    "Then, generate some normal distributed noise with the command\n",
    "\n",
    "```python\n",
    "e = np.sqrt(sigma2) * np.random.randn(N)\n",
    "```\n",
    "\n",
    "where `sigma2` is the variance of the noise process `e`, and `N` is the length of the resulting vector.\n",
    "\n",
    "After creating the noise vector, you simulate the ARMA process with the command:\n",
    "```python\n",
    "y = signal.lfilter(C, A, e)\n",
    "```\n",
    "\n",
    "**Important:** When simulating a process containing an AR part, such as an AR or ARMA process, the initial values in the simulated signals will behave differently to the latter values as these are not initiated by earlier values being a part of the process, but with zeros (by default $y_0 = y_{-1}=\\ldots=0$). These will in turn affect the following samples, and so on, with diminishing influence the further you go. As a result, the initial simulated samples will behave somewhat differently from what one expects from the simulated process.\n",
    "\n",
    "A simple way to handle this is to just simulate a longer process than needed, and then omitting the initial samples. Often, one use a significant \"buffer\" in this way to avoid any unwanted initial effects to affect the following samples, preferring to exaggerate the number of omitted samples (obviously, this is only done when simulating signals). For almost all simulated processes, one may safely assume that any initial effects will be negligible after, say, 100 samples (and, typically, well before this).\n",
    "\n",
    "**Hint:** It is recommended that you create your own function for simulating data, say `simulate_ARMA()`, that takes the specified parameters as input, as well as the desired data length, and then returns the simulated data. Internally, the function then simulates a longer signal, say 100 samples longer, and then just returns the signal from the end of the simulated signal. By doing this, you will ensure that it is easy for you to simulate new data, and that you do not forget to handle the initial data effects when doing so (this easily happens...).\n",
    "\n",
    "Now simulate `300` samples of the ARMA processes and omit the first 100 samples of each. Proceed to simulate the `y1` and `y2` processes, using `sigma2=1.5`. Plot the two processes using subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ARMA(A, C, sigma2=1.5, N=300, buffer=100, seed=0):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    ??\n",
    "    return y[buffer:]\n",
    "\n",
    "\n",
    "y1 = simulate_ARMA(A1, C1, sigma2=1.5, N=300, buffer=100, seed=0)\n",
    "\n",
    "y2 = simulate_ARMA(A2, C2, sigma2=1.5, N=300, buffer=100, seed=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "ax1.plot(y1)\n",
    "ax1.set_title('Process y1')\n",
    "ax1.set_xlabel('Sample')\n",
    "ax1.set_ylabel('y1')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(y2)\n",
    "ax2.set_title('Process y2')\n",
    "ax2.set_xlabel('Sample')\n",
    "ax2.set_ylabel('y2')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c88b1",
   "metadata": {},
   "source": [
    "### Analyzing the processes\n",
    "\n",
    "As you can see, one of the processes diverges. Why is that? \n",
    "\n",
    "Plot the poles and zeros of the different polynomials to see if this provides a clue.\n",
    "\n",
    "**QUESTION 1:** In Mozquizto, answer question 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pole-zero maps to analyze why one process diverges\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "pzmap(C1, A1, ax=ax1, show=False)\n",
    "ax1.set_title('Pole-Zero Map of y1 (ARMA(2,2))')\n",
    "\n",
    "pzmap(C2, A2, ax=ax2, show=False)\n",
    "ax2.set_title('Pole-Zero Map of y2 (ARMA(1,2))')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc877625",
   "metadata": {},
   "source": [
    "### Covariance function comparison\n",
    "\n",
    "The theoretical covariance function $r_y(k)$ for an ARMA-process can be computed using the Yule-Walker equations using the provided function `kovarians`. \n",
    "\n",
    "The function assumes that the driving noise process has unit variance, i.e., $V(e(t)) = \\sigma^2 = 1$. \n",
    "\n",
    "To instead compute the estimated covariance from a given data set, use the function `xcorr`.\n",
    "\n",
    "Plot to compare the theoretical versus the estimated covariance for `y1` (set `m=20`).\n",
    "\n",
    "Why are the estimated and theoretical covariance functions not identical?\n",
    "\n",
    "**QUESTION 2:** In Mozquizto, answer question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba5b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20  # Number of lags to compute\n",
    "\n",
    "\n",
    "sigma2 = 1.5\n",
    "r_theo, tau = kovarians(C1, A1, m)\n",
    "r_theo = r_theo * sigma2  # Scale by actual noise variance\n",
    "\n",
    "# Compute estimated covariance from data using\n",
    "lags, r_est = xcorr(y1, maxlag=m, biased=True)\n",
    "r_est = r_est[m:]  \n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stem(tau, r_theo, linefmt='b-', markerfmt='bo', basefmt=' ', label='Theoretical')\n",
    "plt.stem(tau, r_est, linefmt='r-', markerfmt='rx', basefmt=' ', label='Estimated')\n",
    "plt.xlabel('Lag k')\n",
    "plt.ylabel('Covariance')\n",
    "plt.title('Theoretical vs Estimated Covariance Function')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf3930",
   "metadata": {},
   "source": [
    "### Model estimation and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22322ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis of y1 using ACF, PACF, and normplot take a look on how plotACFnPACF() and normplot() is implemented in analysis.py: \n",
    "plotACFnPACF(??)\n",
    "normplot(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140e1daa",
   "metadata": {},
   "source": [
    "Estimate the model you wish to validate using the LS-based method for an AR($n_a$) model or using the ML-based method for an ARMA($n_a$, $n_c$) model. \n",
    "\n",
    "For estimation, Python uses the `estimateARMA` function which can estimate both AR and ARMA models by specifying the model orders.\n",
    "\n",
    "To calculate the error residual of your estimated model, you can filter your data through the inverse filter of your model using:\n",
    "\n",
    "```python\n",
    "e_hat = signal.lfilter(model.A, model.C, y)\n",
    "```\n",
    "\n",
    "**Important:** An important thing to note when computing the residual using filtering is that the initial values of the output will be corrupted, as the AR part will need non-existing samples to initialise the first states, therefore setting these to zeros. \n",
    "\n",
    "This means that the first $n_a$ samples will be corrupted and should **always** be removed before **any** further processing is done.\n",
    "\n",
    "Try changing the order of the $A(z)$ polynomial and plot the first 20 samples of `e_hat`. Can you see that the initial $n_a$ samples are corrupted? \n",
    "\n",
    "To avoid this from causing problems for you, you should **always** remove the first $n_a$ samples when filtering any process that you are modelling.\n",
    "\n",
    "**Hint:** As you will do the filtering operation many times, and it is very easy to forget omitting these $n_a$ initial samples, it is highly recommended that you create your own function `my_filter` that does the filtering and omits the samples; that way you will not forget this. \n",
    "\n",
    "It is only a couple of lines of code, but it will likely save you a lot of pain... However, also note that there are cases when you do not want to do this automatically, especially in the case of prediction that we will cover later - in that case, you will filter two different sequences with different lengths - and then want omit the same number of samples as the longer filter for both sequences. In this case, you do **not** want to use `my_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beda0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(A, C, y):\n",
    "    ??\n",
    "    return e_hat[na:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31224551",
   "metadata": {},
   "source": [
    "### Demonstration of Initial Sample Corruption\n",
    "\n",
    "Let's examine the issue with initial sample corruption when filtering. \n",
    "\n",
    "We'll compare filtering with and without removing the initial corrupted samples. Notice that the initial residuals are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_demo = np.array([1, -1.79, 0.84])\n",
    "C_demo = np.array([1, -0.18, -0.11])\n",
    "\n",
    "e_hat_corrupted = signal.lfilter(A_demo, C_demo, y1)\n",
    "\n",
    "e_hat_clean = my_filter(A_demo, C_demo, y1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.arange(20), e_hat_corrupted[:20], 'o-', markersize=6, color='C0', label='Corrupted (first 20)')\n",
    "na = len(A_demo) - 1\n",
    "plt.axvspan(-0.5, na - 0.5, alpha=0.12, color='red', label=f'Corrupted region (first {na} samples)')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Residual value')\n",
    "plt.title('Residuals: corrupted (first 20 samples)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434347a",
   "metadata": {},
   "source": [
    "### Finding the appropriate model order\n",
    "\n",
    "Proceed to find an appropriate model for the process by adding one extra parameter at a time, and then analyze the residual using ACF, PACF, and normplot. \n",
    "\n",
    "Make a note of the FPE for each of the models you examine. Is the FPE minimized for the correct model order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101be725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate AR model different orders\n",
    "\n",
    "\n",
    "ar1_model = estimateARMA(y1, A=1, C=0, plot=False)\n",
    "e_hat_ar1 = my_filter(ar1_model.A, ar1_model.C, y1)\n",
    "print(f\"AR(1) - A: {ar1_model.A}, FPE: {ar1_model.FPE:.4f}\\n\")\n",
    "\n",
    "# Analyze AR(1) residuals (best AR model based on PACF)\n",
    "print(\"AR(1) Residual Analysis:\")\n",
    "plotACFnPACF(e_hat_ar1, noLags=40, signLvl=0.05)\n",
    "normplot(e_hat_ar1)\n",
    "whiteness_test(e_hat_ar1, alpha=0.05)\n",
    "\n",
    "# test other AR models 1,2,3,4,5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291e0fa",
   "metadata": {},
   "source": [
    "### Estimating ARMA Models\n",
    "\n",
    "Now let's estimate ARMA models with different combinations of $n_a$ and $n_c$ from 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate ARMA model \n",
    "\n",
    "# ARMA(1,1)\n",
    "print(\"Estimating ARMA(1,1)...\")\n",
    "arma11_model = estimateARMA(y1, A=1, C=1, plot=False)\n",
    "e_hat_arma11 = my_filter(arma11_model.A, arma11_model.C, y1)\n",
    "print(f\"ARMA(1,1) - A: {arma11_model.A}, C: {arma11_model.C}\")\n",
    "print(f\"FPE: {arma11_model.FPE:.4f}\\n\")\n",
    "\n",
    "# Analyze ARMA(1,1) residuals\n",
    "print(\"ARMA(1,1) Residual Analysis:\")\n",
    "plotACFnPACF(e_hat_arma11, noLags=40, signLvl=0.05)\n",
    "normplot(e_hat_arma11)\n",
    "whiteness_test(e_hat_arma11, alpha=0.05)\n",
    "\n",
    "# test other ARMA models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d3e2d",
   "metadata": {},
   "source": [
    "### Examination Question 3\n",
    "\n",
    "**QUESTION 3:** In Mozquizto, answer question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4776cff3",
   "metadata": {},
   "source": [
    "## 2.2 Model order estimation of an ARMA-process\n",
    "\n",
    "In the file `data.dat` you will find 200 observations of the ARMA(1,1)-process\n",
    "\n",
    "$$y_t - 0.6 y_{t-1} = e_t + 0.8 e_{t-1}$$\n",
    "\n",
    "Assuming that you do not know what might be an appropriate model structure for the process, we will begin by trying to estimate it using an AR($p$) model, for $p=1,\\ldots,5$. \n",
    "\n",
    "When examining which model order to use, see the parameter estimates and some statistics. \n",
    "\n",
    "Try modelling data as an AR($p$) model, for $p=1,\\ldots,5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205db10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from data.dat\n",
    "data = np.loadtxt('../CourseMaterial (1)/CourseMaterial/Code/data/data.dat')\n",
    "orig_noise = np.loadtxt('../CourseMaterial (1)/CourseMaterial/Code/data/noise.dat')\n",
    "\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Number of observations: {len(data)}\")\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(data)\n",
    "plt.title('ARMA(1,1) Process - data.dat')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede81c36",
   "metadata": {},
   "source": [
    "### Try AR($p$) models for $p = 1, \\ldots, 5$\n",
    "\n",
    "To get useful information about the model, try using `.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f005f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR(1) model\n",
    "print(\"=\" * 60)\n",
    "print(\"AR(1) Model\")\n",
    "print(\"=\" * 60)\n",
    "ar1_model = estimateARMA(data, A=1, C=0, plot=False)\n",
    "ar1_model.summary()\n",
    "\n",
    "# Compute residuals\n",
    "e_hat_ar1 = my_filter(ar1_model.A, ar1_model.C, data)\n",
    "\n",
    "# Analyze residuals\n",
    "print(\"\\nAR(1) Residual Analysis:\")\n",
    "plotACFnPACF(e_hat_ar1, noLags=30, signLvl=0.05)\n",
    "normplot(e_hat_ar1)\n",
    "whiteness_test(e_hat_ar1, alpha=0.05)\n",
    "\n",
    "# test other AR models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3802fe9",
   "metadata": {},
   "source": [
    "### Examination Question 4\n",
    "\n",
    "**In Mozquizto, answer question 4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22fd9e8",
   "metadata": {},
   "source": [
    "### Try ARMA($p,q$) models\n",
    "\n",
    "Instead, try to model the data using ARMA($p,q$) models, for $p,q = 1, 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6212fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARMA(1,1) model\n",
    "print(\"=\" * 60)\n",
    "print(\"ARMA(1,1) Model\")\n",
    "print(\"=\" * 60)\n",
    "arma11_model = estimateARMA(data, A=1, C=1, plot=False)\n",
    "arma11_model.summary()\n",
    "\n",
    "# Compute residuals\n",
    "e_hat_arma11 = my_filter(arma11_model.A, arma11_model.C, data)\n",
    "\n",
    "# Analyze residuals\n",
    "print(\"\\nARMA(1,1) Residual Analysis:\")\n",
    "plotACFnPACF(e_hat_arma11, noLags=30, signLvl=0.05)\n",
    "normplot(e_hat_arma11)\n",
    "whiteness_test(e_hat_arma11, alpha=0.05)\n",
    "\n",
    "# Test other ARMA models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a93dee",
   "metadata": {},
   "source": [
    "### Discussion: Model comparison\n",
    "\n",
    "Comparing the models using the variance of the residuals, which was the best model of the ones you considered, i.e., an AR($p$), for $p=1,\\ldots,5$, or an ARMA($p,q$), for $p,q = 1, 2$? \n",
    "\n",
    "Examine the ACF and PACF as well. \n",
    "\n",
    "Which model would you pick if you did not know it was an ARMA(1,1)?\n",
    "\n",
    "**Be prepared to answer this question when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb01c6",
   "metadata": {},
   "source": [
    "## 2.3 Estimation of a SARIMA-process\n",
    "\n",
    "We proceed to examine the seasonal ARMA model\n",
    "\n",
    "$$\n",
    "A(z)\\nabla_s y_t = C(z)e_t,\n",
    "$$\n",
    "\n",
    "with $\\nabla_s = (1-z^{-s})$.\n",
    "\n",
    "We begin with simulating data, and then use the ML-based estimator to re-estimate the parameters to see how this is done. Simulate the process using the following polynomials:\n",
    "\n",
    "$$\n",
    "A(z) = 1 - 1.5z^{-1} + 0.7z^{-2},\n",
    "$$\n",
    "\n",
    "$$\n",
    "C(z) = 1 - 0.5z^{-12},\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "A_{12}(z) = \\nabla_{12} = (1 - z^{-12}),\n",
    "$$\n",
    "\n",
    "and form the polynomial\n",
    "\n",
    "$$\n",
    "A^\\star(z) = A(z)A_{12}(z).\n",
    "$$\n",
    "\n",
    "We here set the seed just to get the same result as used in Mozquizto. Simulate 600 samples (100 samples should be removed to avoid initial corruption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the polynomials\n",
    "np.random.seed(0)\n",
    "A = np.array([1, -1.5, 0.7])\n",
    "C = np.array([1] + [0]*11 + [-0.5])  # [1, 0, 0, ..., 0, -0.5] with 12 zeros\n",
    "A12 = np.array([1] + [0]*11 + [-1])  # [1, 0, 0, ..., 0, -1] with 12 zeros\n",
    "\n",
    "A_star = np.convolve(A, A12)\n",
    "\n",
    "\n",
    "# Simulate the process\n",
    "N = 600\n",
    "buffer = 100\n",
    "y = simulate_ARMA(A_star, C, sigma2=1.0, N=N, buffer=buffer)\n",
    "\n",
    "# Plot the simulated data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y)\n",
    "plt.title('Simulated Seasonal ARMA Process')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('y(t)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048efe7",
   "metadata": {},
   "source": [
    "### Basic analysis\n",
    "\n",
    "Perform basic analysis of the signal using ACF, PACF, and normplot. What characteristics does it have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some basic analysis on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a9621",
   "metadata": {},
   "source": [
    "The ringing behaviour you see in both the ACF and the PACF indicates strong seasonality. To be able to model the process taking the season into account, you create a differentiated process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e58b1",
   "metadata": {},
   "source": [
    "### Remove the seasonal component\n",
    "\n",
    "To do so, start by removing the season by filtering the data with $A_{12}(z) = (1 - z^{-12})$.\n",
    "\n",
    "**Note:** We again have to omit the initial samples - otherwise these initial corrupt samples will harm our continuing processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimate an AR(2) model\n",
    "\n",
    "Building a model to this data, one parameter at a time, could for instance mean starting with an AR(2) model. Use the estimator to estimate $a_1$ and $a_2$.\n",
    "# Plot the deseasonalized data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_s)\n",
    "plt.title('Deseasonalized Data')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('y_s(t)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec31e3",
   "metadata": {},
   "source": [
    "Building a model to this data, one parameter at a time, could\n",
    "for instance mean starting with an AR(1), as an initial guess, redo the basic\n",
    "analysis and then proceed to an AR(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510df17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple model for the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bf6e5",
   "metadata": {},
   "source": [
    "Form the residual and plot its ACF and PACF. What characteristics does it have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbe6da1",
   "metadata": {},
   "source": [
    "### Add MA(12) component\n",
    "\n",
    "To add a single parameter of a higher order, i.e., to set some parameters fixed to a value, we specify which C coefficients are free to be estimated. \n",
    "\n",
    "For the C-polynomial, we have thus made all parameters fixed except for $c_{12}$. Include this parameter in the model and estimate $a_1$, $a_2$, and $c_{12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf50011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate ARMA(2, 12) with only c_12 free (c_1 through c_11 fixed at 0)\n",
    "# We specify which C coefficients are free to be estimated\n",
    "C_free = np.array([1] + [0]*11 + [1])  # c_0 and c_12 are free (c_0 is always 1)\n",
    "\n",
    "model_arma = estimateARMA(y_s, A=2, C=12, C_free=C_free, plot=False)\n",
    "model_arma.summary()\n",
    "\n",
    "# Compute residuals\n",
    "e_hat_arma = my_filter(model_arma.A, model_arma.C, y_s)\n",
    "\n",
    "# Analyze residuals\n",
    "plotACFnPACF(e_hat_arma, noLags=30, signLvl=0.05)\n",
    "normplot(e_hat_arma)\n",
    "whiteness_test(e_hat_arma, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141e5af",
   "metadata": {},
   "source": [
    "### Model quality\n",
    "\n",
    "The main questions to ask are now:\n",
    "\n",
    "- Did this remove the season of the resulting model residual?\n",
    "- Is the residual white noise?\n",
    "- Are the ACF and/or PACF coefficients Gaussian distributed so that you can trust your whiteness test?\n",
    "- Are the estimated parameters significant?\n",
    "\n",
    "Compare the estimated parameters with the values used to simulate the process. \n",
    "\n",
    "Examine how the quality of the estimates improve if you redo the simulation but instead using $N=10000$ samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356249bf",
   "metadata": {},
   "source": [
    "### Examination Question 5\n",
    "\n",
    "**In Mozquizto, answer question 5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81315bba",
   "metadata": {},
   "source": [
    "### Modelling steps summary\n",
    "\n",
    "In summary, the typical modelling steps used when constructing a time series model generally works in accordance with the following steps:\n",
    "\n",
    "1. Is there a trend? Try removing it.\n",
    "2. Is there any seasonality? Try removing it.\n",
    "3. Iterate between\n",
    "   - (a) Which is the lowest order strong AR- or MA-component? Try removing it by including it in the model. Always begin with the strongest AR-component, then inspect the MA-components in the next iteration.\n",
    "   - (b) Is the residual white noise? If not, go to (a). Can you trust your test, i.e., is the ACF and/or PACF Gaussian distributed? If not, what are the consequences? Should you allow for more parameters?\n",
    "4. Are all parameter estimates statistically significant? If not, redo the analysis and use a different model structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3d030b",
   "metadata": {},
   "source": [
    "### Hint: Testing with simulated data\n",
    "\n",
    "**Hint:** If (or, rather, when) you want to check that your code is correct, it is always wise to test it using simulated data, preferably using a lot of samples. \n",
    "\n",
    "Simply simulate a process that has roughly the same characteristics as the process you are examining (typically using the model you have estimated) and check that your code predicts the simulated process well. \n",
    "\n",
    "For a long sequence, it should work, otherwise, there is most likely a bug somewhere... \n",
    "\n",
    "It is highly recommended that you **always** do this when modelling data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb2439",
   "metadata": {},
   "source": [
    "### Discussion: Incorporating differentiation\n",
    "\n",
    "Can you improve your model by not removing the trend and/or season separately, but rather incorporating these parts in your model and estimate the corresponding coefficients? \n",
    "\n",
    "That is, do you get better result if you include the differentiation in your $A(z)$ polynomial? Try it out!\n",
    "\n",
    "**Question:** Can you incorporate the differentiation $\\nabla_{12}$ in the model $A(z)$ instead of first removing the season?\n",
    "\n",
    "Is the resulting model better in some sense, i.e., is the variance of the model residual lower? \n",
    "\n",
    "If you examine the estimated parameters, do they match the internal structure? \n",
    "\n",
    "Can you think of any pros and cons of incorporating the differentiation in the model in this way?\n",
    "\n",
    "**Be prepared to answer these questions when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79120e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and have the differentiation in the A() polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099d6eb",
   "metadata": {},
   "source": [
    "## 2.4 Estimation on real data\n",
    "\n",
    "We now proceed to use our knowledge on estimation of SARIMA-models on real data. Load the temperature measurements from Svedala. Using the working order stated above, create a suitable model for this data. Remember to reestimate all your parameters if you change your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Svedala temperature data\n",
    "svedala_file = '../data/svedala.mat'\n",
    "mat_data = scipy.io.loadmat(svedala_file)\n",
    "\n",
    "print(\"Keys in .mat file:\", mat_data.keys())\n",
    "\n",
    "svedala = mat_data['svedala'].flatten()\n",
    "\n",
    "print(f\"Loaded {len(svedala)} temperature measurements\")\n",
    "print(f\"Data shape: {svedala.shape}\")\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(svedala)\n",
    "plt.title('Svedala Temperature Data')\n",
    "plt.xlabel('Time (months)')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc28df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate a model for the Svedala data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf0687",
   "metadata": {},
   "source": [
    "### Basic analysis of Svedala data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some basic analysis on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ec50e",
   "metadata": {},
   "source": [
    "### Examination Question 6\n",
    "\n",
    "**In Mozquizto, answer question 6.**\n",
    "\n",
    "What parameter estimates did you get? \n",
    "\n",
    "Can you improve the model by not differentiating the data? Why or why not?\n",
    "\n",
    "**Be prepared to answer these questions when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed67199",
   "metadata": {},
   "source": [
    "### Discussion: What parameter estimates did you get? Can you improve the model by not differentiating the data? Why or why not?\n",
    "\n",
    "**Be prepared to answer these questions when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290df8f",
   "metadata": {},
   "source": [
    "## 2.5 (optional) Examine the project data\n",
    "\n",
    "Why not now load the project data and try to build an ARMA model for the output data? \n",
    "\n",
    "Can you make the model residual white without using too many parameters? \n",
    "\n",
    "Do you have insignificant parameters in the model? \n",
    "\n",
    "Examine the variance of the model residual for the different models - do you need to include all parameters or can you remove some without increasing the variance noticeably while retaining an \"almost\" white residual?\n",
    "\n",
    "**Hint:** The above steps will typically be the first part of your work on the project, so the time you spend on this now will be time saved later on..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
